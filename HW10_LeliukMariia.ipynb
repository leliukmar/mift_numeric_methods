{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1"
      ],
      "metadata": {
        "id": "Q00pW0HMTdNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Estimate biases of the coins p1 and p2 by optimizing directly the marginal likelihood:\n",
        "$$\n",
        "p_1, p_2 = argmax_{p_1, p_2} \\sum_Z P(X|Z, p1, p2)\n",
        "$$"
      ],
      "metadata": {
        "id": "Z6wVqJ0SXCm5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "P(X|Z, Q) = P_1(X|Z, Q) * P_2(X|Z, Q) *... * P_5(X|Z, Q)\n",
        "$$\n",
        "\n",
        "$$\n",
        "P_i(X|Z, Q) ‚àù p_{z_i}^{k_i} (1 - p_{z_i})^{10 - k_i}\n",
        "$$\n",
        "\n",
        ", where\n",
        "* $i$ - number of experiment: 1 - 5\n",
        "* $z_i$ - coin chosen in i-th experiment\n",
        "* $p_{z_i}$ - probability of HEAD for coin $z_i$\n",
        "* $k_i$ - number of times when we had HEAD in i-th experiment"
      ],
      "metadata": {
        "id": "Jtqv-D3mXi_w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6DegbiUtQDSQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "jax.config.update(\"jax_enable_x64\", True)\n",
        "from scipy import optimize\n",
        "\n",
        "A = np.array([\n",
        "    'HTTTHHTHTH',\n",
        "    'HHHHTHHHHH',\n",
        "    'HTHHHHHTHH',\n",
        "    'HTHTTTHHTT',\n",
        "    'THHHTHHHTH'\n",
        "])\n",
        "tosses = 5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "Z = list(itertools.product(range(2), repeat=tosses))"
      ],
      "metadata": {
        "id": "WqO8uEKJYzUG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prob(coins_id, p1, p2):\n",
        "    flag_0 = coins_id == 0\n",
        "    flag_1 = ~flag_0\n",
        "    counts_1 = {c: np.sum([exp.count(c) for exp in A[flag_0]]) for c in ['H', 'T']}\n",
        "    counts_2 = {c: np.sum([exp.count(c) for exp in A[flag_1]]) for c in ['H', 'T']}\n",
        "    return p1**counts_1['H']*(1-p1)**counts_1['T'] * p2**counts_2['H']*(1-p2)**counts_2['T']\n",
        "\n",
        "def likelihood(p):\n",
        "  return jnp.sum( jnp.array([prob(jnp.array(z), p[0], p[1]) for z in Z]))\n",
        "\n",
        "likelihood([0.8, 0.6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLbqnk-TY8RA",
        "outputId": "7938d1c9-2699-499d-f49d-d50e15aefbbc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(5.05329359e-13, dtype=float64)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import optimize\n",
        "from scipy.optimize import Bounds\n",
        "from scipy.integrate import dblquad\n",
        "\n",
        "bounds = Bounds([0.0, 0.0], [1.0, 1.0])\n",
        "\n",
        "res = dblquad(lambda x, y: likelihood([x, y]), 0, 1, 0, 1)\n",
        "norm_coeff = 1.0 / res[0]\n",
        "\n",
        "def loss(p):\n",
        "  return -norm_coeff * likelihood(p)\n",
        "\n",
        "p0 = np.random.uniform(low=0.0, high=1.0, size=(2,))\n",
        "res = optimize.minimize(loss,\n",
        "                        p0,\n",
        "                        jac = jax.grad(loss),\n",
        "                        hess=jax.hessian(loss),\n",
        "                        method='trust-constr',\n",
        "                        bounds=bounds)\n",
        "\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1phZVTqtd69p",
        "outputId": "f6afd649-6c80-42db-d2fe-adbb0f63be4f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           message: `gtol` termination condition is satisfied.\n",
              "           success: True\n",
              "            status: 1\n",
              "               fun: -6.5625569443091685\n",
              "                 x: [ 5.196e-01  7.968e-01]\n",
              "               nit: 56\n",
              "              nfev: 74\n",
              "              njev: 22\n",
              "              nhev: 22\n",
              "          cg_niter: 46\n",
              "      cg_stop_cond: 4\n",
              "              grad: [-2.981e-08 -6.052e-08]\n",
              "   lagrangian_grad: [-3.263e-09 -1.979e-09]\n",
              "            constr: [array([ 5.196e-01,  7.968e-01])]\n",
              "               jac: [<2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
              "                    \twith 2 stored elements in Compressed Sparse Row format>]\n",
              "       constr_nfev: [0]\n",
              "       constr_njev: [0]\n",
              "       constr_nhev: [0]\n",
              "                 v: [array([ 2.654e-08,  5.854e-08])]\n",
              "            method: tr_interior_point\n",
              "        optimality: 3.262670632182317e-09\n",
              "  constr_violation: 0.0\n",
              "    execution_time: 27.31625747680664\n",
              "         tr_radius: 1.0\n",
              "    constr_penalty: 1.0\n",
              " barrier_parameter: 2.048000000000001e-09\n",
              " barrier_tolerance: 2.048000000000001e-09\n",
              "             niter: 56"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Best estimation of coins biases p_1 and p_2 ={res.x}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JmryM8ceat7",
        "outputId": "6f952cbb-b5b8-439b-f873-91bdccb40f1c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best estimation of coins biases p_1 and p_2 =[0.51958312 0.79678907]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yw0qcPoMih3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Estimate biases of the coins p1 and p2 by running iterative EM algorithm."
      ],
      "metadata": {
        "id": "8fJHXmKAiiAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HT_stats = jnp.array([[A[i].count(c) for c in ['H', 'T']] for i in range(tosses)])\n",
        "HT_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSpqFZz2pGCI",
        "outputId": "59cf4232-0d6b-41eb-d16b-f264351c7c29"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[5, 5],\n",
              "       [9, 1],\n",
              "       [8, 2],\n",
              "       [4, 6],\n",
              "       [7, 3]], dtype=int64)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_probs(p0_init, p1_init):\n",
        "  # 1. calculate probabilities that in each experiment certain coin was chosen\n",
        "  probs = jnp.array([\n",
        "      [p0_init**HT_stats[i][0] * (1 - p0_init)**HT_stats[i][1], p1_init**HT_stats[i][0] * (1 - p1_init)**HT_stats[i][1]]\n",
        "      for i in range(tosses)\n",
        "  ])\n",
        "  probs = probs / probs.sum(axis=1, keepdims=True)\n",
        "\n",
        "  # 2. calculate coefficients of log-likelihood of choosing coins across all tosses\n",
        "  # logL = coeff[0]*ln(p_0) + coeff[1]*ln(1 - p_0) + coeff[2]*ln(p_1) + coeff[3]*ln(1 - p_1)\n",
        "  coeff = jnp.array([\n",
        "      [HT_stats[i][0]* probs[i][0], HT_stats[i][1]* probs[i][0], HT_stats[i][0]* probs[i][1], HT_stats[i][1]* probs[i][1]]\n",
        "      for i in range(tosses)\n",
        "  ])\n",
        "  coeff = jnp.sum(coeff, axis=0)\n",
        "\n",
        "  # 3. maximize log-likelihood for p_0 and p_1 by taking its partial deriviatives equal to zero\n",
        "  p0_next = coeff[0] / (coeff[0] + coeff[1])\n",
        "  p1_next = coeff[2] / (coeff[2] + coeff[3])\n",
        "\n",
        "  log_likelihood = coeff[0]*jnp.log(p0_next) + coeff[1]*jnp.log(1-p0_next) + \\\n",
        "                   coeff[2]*jnp.log(p1_next) + coeff[3]*jnp.log(1-p1_next)\n",
        "\n",
        "  return p0_next, p1_next, log_likelihood\n"
      ],
      "metadata": {
        "id": "F2sU7M_Ci4k4"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_probs(p0_init, p1_init, tolerace=1e-6, max_iter=1000000):\n",
        "  prev_ll = -1e10\n",
        "\n",
        "  p0 = p0_init\n",
        "  p1 = p1_init\n",
        "  for step in range(max_iter):\n",
        "    p0, p1, ll = get_probs(p0, p1)\n",
        "    if abs(ll - prev_ll) < tolerace:\n",
        "      print(f\"Converged in {step + 1} iterations\")\n",
        "      return p0, p1\n",
        "    prev_ll = ll\n",
        "\n",
        "  print(f\"No convergence, stopped by reaching max iteration count\")\n",
        "  return p0, p1"
      ],
      "metadata": {
        "id": "EywrHwaKxJLJ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_em_algorithm(p0_init, p1_init):\n",
        "  p0, p1 = find_probs(p0_init, p1_init)\n",
        "  print(f\"Optimal values are: [{p0}, {p1}]\")"
      ],
      "metadata": {
        "id": "h1NbRYv0zade"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_em_algorithm(0.5, 0.55)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t7i4zw1zudJ",
        "outputId": "4baff2fc-82fe-40ea-abbb-7e29ee72201e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged in 21 iterations\n",
            "Optimal values are: [0.5195831374972835, 0.7967890630579104]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets try some othe initial values\n",
        "run_em_algorithm(0.1, 0.9)\n",
        "run_em_algorithm(0.01, 0.0001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOrTf2OSz2-u",
        "outputId": "6f1997f6-e3ed-4e24-ea98-8cce642a3a60"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged in 17 iterations\n",
            "Optimal values are: [0.5195830644314472, 0.7967890516788051]\n",
            "Converged in 14 iterations\n",
            "Optimal values are: [0.7967885064073513, 0.5195823690774435]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, resulting values of probabilities p1 and p2 are almost the same as in the first step."
      ],
      "metadata": {
        "id": "QReXY-JW0FWx"
      }
    }
  ]
}